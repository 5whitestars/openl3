# openl3

[![Documentation Status](https://readthedocs.org/projects/openl3/badge/?version=latest)](http://openl3.readthedocs.io/en/latest/?badge=latest)
[![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)
[![Build Status](https://travis-ci.org/marl/openl3.svg?branch=master)](https://travis-ci.org/marl/openl3)
[![Coverage Status](https://coveralls.io/repos/github/marl/openl3/badge.svg?branch=master)](https://coveralls.io/github/marl/openl3?branch=master)
[![PyPI](https://img.shields.io/badge/python-2.7%2C%203.4%2C%203.5%2C%203.6-blue.svg)]()

Open-source deep audio and image embeddings.

Details of training the models can be found in the following paper:

Look, Listen, and Learn More: Design Choices for Deep Audio Embeddings<br/>
Jason Cramer, Ho-Hsiang Wu, Justin Salamon and Juan Pablo Bello<br/>
Under review, 2018.